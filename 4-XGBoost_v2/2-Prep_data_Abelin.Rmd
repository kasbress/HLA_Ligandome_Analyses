---
title: "Generate peptide database"
author: "Kaspar Bresser"
date: "22/03/2024"

output: 
  github_document:
    toc: true
  html_document: 
    theme: simplex
    highlight: pygments
#    code_folding: show
    self_contained: TRUE
    toc: yes
    toc_float:
      collapsed: no
---



```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      message=FALSE,
                      eval = F,
                      autodep  = TRUE,
                      cache = FALSE,
#                     comment = NA,
                      fig.width = 5,
                      fig.asp = 0.618,
                      fig.align = "center")
```

```{r startup, eval=T}
library(babelgene)
library(tidyverse)
library(readxl)
library(furrr)
```


## Import ligands


```{r check_sheets, eval=T}
excel_sheets("Data/Abelin_Immunity_data.xlsx")[6:19]
```



```{r import_ligand_data, eval=T}
alleles <- excel_sheets("Data/Abelin_Immunity_data.xlsx")[6:19]

excel.file <- "Data/Abelin_Immunity_data.xlsx"

tibble(data = map(alleles, ~read_excel(excel.file, sheet = . )), allele = alleles) %>% 
  mutate(data = map(data, ~select(., sequence, entry_name))) %>% 
  unnest(data) %>% 
  rename(UCSC.id = entry_name) %>% 
  mutate(UCSC.id = str_remove(UCSC.id, "\\..+"),
         sequence = toupper(sequence)) -> broad.HLA.data
  
broad.HLA.data
```

Import master sheet

```{r get.p, eval=T}
master.sheets <- read_tsv("Data/Abelin_immunity_data.tsv")
```

Prep master sheet

```{r get.p2, eval=T}
master.sheets %>% 
  pivot_longer(cols = everything(), names_to = "allele", values_to = "sequence", values_drop_na = T) %>% 
  mutate(sequence = toupper(sequence),
         allele = str_remove(allele, ":")) -> master.sheets
```

Get conversions for IDs to swissprot

```{r expand_conversion, eval=T}
conversion.table <- read_tsv("Data/swissprot_conversion_2023_12_21.tsv.gz")

conversion.table %>% 
  transmute(swissprot.id = Entry, UCSC.id = str_remove(UCSC, "\\..+")) -> conversion.table
```


Add swissprot IDs and only retain peptides in master sheet

```{r, eval=TRUE}
broad.HLA.data %>% 
  inner_join(conversion.table) %>% 
  semi_join(master.sheets, by = c("allele", "sequence")) %>% 
  distinct(sequence, allele, .keep_all = T) -> broad.HLA.data

broad.HLA.data
```



Subsample the peptide pools to get a more workable number, 500 is slightly under the smallest allele-set. 

```{r subsample, eval=TRUE}
"../2-random_forest_analyses/Data/Protein_per_Uniprot_entry_library_v3.csv.zip" %>% 
  read_tsv() %>% 
  pull(Entry) -> IDs.in.library

broad.HLA.data %>% 
  filter(nchar(sequence) %in% 9:11) %>%  
  filter(swissprot.id %in% IDs.in.library) %>% 
  group_by(allele) %>% 
  slice_sample(n = 500) %>% 
  mutate(ligand = TRUE) %>% 
  ungroup() -> filtered.peptides

filtered.peptides

```

```{r}
write_tsv(filtered.peptides, "Output/Abelin/Broad_peptides_subsample.tsv")
```


## Select decoys

Import UniProt sequences, use the rna expression table to make an ensembl/UniProt matching table.

Define a function that, for each allele: (1) Checks which sequences were detected for that allele, (2) samples an excess of proteins from the uniprot table weighted by their length, (3) then for each sample extracts a 9mer, (4) Remove detected peptides, filter for uniqueness and down sample to 350,000. 


```{r import_uniprot}
uniprot <- read_csv("Data/UniProt_reviewed_input.tsv") %>% rename(swissprot_id = "sequence_id")


get_peptide <- function(a, pep.len){
  broad.HLA.data %>% 
    filter(allele == a) %>% 
    filter(nchar(sequence) == pep.len) %>% 
    pull(sequence) %>% 
    toupper() -> s
  
    amount.needed <- nrow(filter(filtered.peptides, allele == a & nchar(sequence) == pep.len))*10
  

    uniprot %>% 
      mutate(len = nchar(sequence)) %>% 
      slice_sample(n = amount.needed*2, weight_by = len, replace = T) %>% 
      rowwise() %>% 
      mutate(number = sample(1:(nchar(sequence)-pep.len), 1),
           sequence = str_sub(sequence, number, number+(pep.len-1))) %>% 
      ungroup() %>% 
      filter(!(sequence %in% s)) %>% 
      transmute(sequence = sequence, swissprot.id = swissprot_id, allele = a, ligand = FALSE) %>% 
      filter(swissprot.id %in% IDs.in.library) %>% 
      distinct(sequence, .keep_all = T) %>% 
      slice_sample(n = amount.needed)
}

decoys <- map2_dfr(rep(alleles, 3), rep(c(9,10,11), each = length(alleles)), get_peptide)

filtered.peptides %>% 
  select(!UCSC.id) %>% 
  bind_rows(decoys) -> test.set


test.set %>% 
  count(allele, ligand, nchar(sequence))

```

Write out the table and peptide files

```{r, echo=FALSE}
test.set %>% 
  transmute(pep.len = paste0(nchar(sequence), "AA"), sequence = sequence, allele = allele) %>% 
  unite("info", allele, pep.len) %>% 
  nest(data = sequence) %>% 
  mutate(peptides = map(data, pull, sequence),
         peptides = set_names(peptides, info)) %>% 
  pull(peptides) %>% 
  map2(names(.), ~write_lines(.x, paste0("./Output/Abelin/peptides/Broad_Test_Peptides_", .y, ".tsv")))

write_tsv(test.set, "./Output/Abelin/Broad_Train_Table.tsv")
```

## Run netMHCpan

Run system command for netMHCpan, for each allele. 

```{r echo=FALSE}
args_netMHC <- function(fil){
 
   allele <- str_split_1(fil, "_")[4]
   pep.len <- str_extract(str_split_1(fil, "_")[5], "\\d+")
  
  c(
    paste0("-a HLA-", sub("(.{3})(.*)", "\\1:\\2", allele)),
    paste0("-f ", fil),
    "-p",
    "-rth 0.0",
    "-rlt 0.0",
    paste0("-l ", pep.len),
    "-t -100"
  )
}


files <- list.files("Output/Abelin/peptides", full.names = T)

plan(multisession, workers = 6)

future_map(files, ~system2(command = "netMHCpan", 
                      args = args_netMHC(.), 
                      stdout  = paste0("./Output/Abelin/netMHCpan_predictions/", str_split_1(., "/")[4])))


```


Define function to read in predictions for each peptide length, cleanup the netMHC output, and combine them in a single tsv file

```{r}
combine_and_clean <- function(allele){

  file.list <- list.files("./Output/Abelin/netMHCpan_predictions/", pattern = allele)
  file.list <- paste0("./Output/Abelin/netMHCpan_predictions/", file.list)
  
  file.list %>% 
    map(read_lines) %>% 
    map(~.[grepl("   1 HLA", .)]) %>% 
    unlist() %>% 
    c(" Pos         MHC        Peptide      Core Of Gp Gl Ip Il        Icore        Identity  Score_EL %Rank_EL", .) %>% 
    write_lines(paste0("./Output/Abelin/netMHCpan_predictions_clean/", allele,".tsv"))
  
  gc()
}
```


Apply the function for each allele

```{r}

map(alleles, combine_and_clean)
```




## Run netMHCpanExp

Run system command for netMHCpan, for each allele. 

```{r echo=FALSE}
args_netMHC <- function(fil){
 
   allele <- str_split_1(fil, "_")[4]
   pep.len <- str_extract(str_split_1(fil, "_")[5], "\\d+")
  
  c(
    paste0("-a HLA-", sub("(.{3})(.*)", "\\1:\\2", allele)),
    paste0("-f ", fil),
    "-p",
    "-rth 0.0",
    "-rlt 0.0",
    paste0("-l ", pep.len),
    "-t -100",
    "-inpfmt 0"
  )
}



files <- list.files("Output/Abelin/peptides", full.names = T)

plan(multisession, workers = 6)

future_map(files, ~system2(command = "netMHCpanExp", 
                      args = args_netMHC(.), 
                      stdout  = paste0("./Output/Abelin/netMHCpanExp_predictions/", str_split_1(., "/")[4])))


```


Define function to read in predictions for each peptide length, cleanup the netMHC output, and combine them in a single tsv file

```{r}
combine_and_clean <- function(allele){

  file.list <- list.files("./Output/Abelin/netMHCpanExp_predictions/", pattern = allele)
  file.list <- paste0("./Output/Abelin/netMHCpanExp_predictions/", file.list)
  
  file.list %>% 
    map(read_lines) %>% 
    map(~.[grepl("   1 HLA", .)]) %>% 
    unlist() %>% 
    c(" Pos         MHC        Peptide      Core Of Gp Gl Ip Il        Icore        Identity  Score_EL %Rank_EL", .) %>% 
    write_lines(paste0("./Output/Abelin/netMHCpanExp_predictions_clean/", allele,".tsv"))
  
  gc()
}
```


Apply the function for each allele

```{r}

map(alleles, combine_and_clean)
```




Import the tables and combine into single table.

```{r}
files <- list.files("./Output/Abelin/netMHCpan_predictions_clean/")

alleles <- str_split_i(files, "\\.", 1)

tibble(allele = alleles, 
       dat = map(files, ~read_table(paste0("./Output/Abelin/netMHCpan_predictions_clean/", .)))) %>% 
  unnest(dat) -> train.table.NetMHC

train.table.NetMHC
```


```{r}
files <- list.files("./Output/Abelin/netMHCpanExp_predictions_clean/")

alleles <- str_split_i(files, "\\.", 1)

tibble(allele = alleles, 
       dat = map(files, ~read_table(paste0("./Output/Abelin/netMHCpanExp_predictions_clean/", .)))) %>% 
  unnest(dat) -> train.table.NetMHCexp

train.table.NetMHCexp
```

Add to test table


```{r}
train.table.NetMHC %>% 
  transmute(sequence = Peptide, allele = allele, rank = `%Rank_EL`) %>% 
  nest(netMHC = -allele) -> train.table.NetMHC

train.table.NetMHCexp %>% 
  transmute(sequence = Peptide, allele = allele, rankExp = `%Rank_EL`) %>% 
  nest(netMHCexp = -allele) -> train.table.NetMHCexp

read_tsv("./Output/Abelin/Broad_Train_Table.tsv") %>% 
  nest(train = -allele) %>% 
  inner_join(train.table.NetMHC) %>% 
  inner_join(train.table.NetMHCexp) %>% 
  mutate(train = map2(train, netMHC, ~inner_join(.x, .y, by = c("sequence")))) %>% 
  mutate(train = map2(train, netMHCexp, ~inner_join(.x, .y, by = c("sequence")))) %>% 
  select(-netMHC, -netMHCexp) %>% 
  unnest(train) %>% 
  distinct(allele, sequence, .keep_all = T) %>% 
  na.omit() -> train.table

train.table %>% 
  count(allele, ligand)
```


```{r}
write_tsv(train.table, "Output/Abelin/Broad_Train_Table_All.tsv")
```



